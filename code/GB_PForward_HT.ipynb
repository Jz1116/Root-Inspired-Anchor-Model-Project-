{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.plotting import radviz\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "#import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import svm, preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import Normalizer, StandardScaler\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import BaggingClassifier, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>α [°]</th>\n",
       "      <th>H [mm]</th>\n",
       "      <th>b [mm]</th>\n",
       "      <th>Ls [mm]</th>\n",
       "      <th>γ [N/mm3]</th>\n",
       "      <th>Pmax [N]</th>\n",
       "      <th>Vroot [mm3]</th>\n",
       "      <th>φ [°]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>90.0</td>\n",
       "      <td>19.4114</td>\n",
       "      <td>17.555563</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>9.080644</td>\n",
       "      <td>4534.350557</td>\n",
       "      <td>39.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>90.0</td>\n",
       "      <td>12.9410</td>\n",
       "      <td>41.703709</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>8.758713</td>\n",
       "      <td>3535.876732</td>\n",
       "      <td>39.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>90.0</td>\n",
       "      <td>19.4114</td>\n",
       "      <td>17.555563</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>11.753734</td>\n",
       "      <td>8267.564868</td>\n",
       "      <td>39.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>90.0</td>\n",
       "      <td>12.9410</td>\n",
       "      <td>41.703709</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>10.797683</td>\n",
       "      <td>5796.469487</td>\n",
       "      <td>39.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>90.0</td>\n",
       "      <td>19.4114</td>\n",
       "      <td>17.555563</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>14.095079</td>\n",
       "      <td>23281.011643</td>\n",
       "      <td>39.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   α [°]  H [mm]   b [mm]    Ls [mm]  γ [N/mm3]   Pmax [N]   Vroot [mm3]  \\\n",
       "0     15    90.0  19.4114  17.555563   0.000016   9.080644   4534.350557   \n",
       "1     15    90.0  12.9410  41.703709   0.000016   8.758713   3535.876732   \n",
       "2     15    90.0  19.4114  17.555563   0.000016  11.753734   8267.564868   \n",
       "3     15    90.0  12.9410  41.703709   0.000016  10.797683   5796.469487   \n",
       "4     15    90.0  19.4114  17.555563   0.000016  14.095079  23281.011643   \n",
       "\n",
       "   φ [°]  \n",
       "0  39.33  \n",
       "1  39.33  \n",
       "2  39.33  \n",
       "3  39.33  \n",
       "4  39.33  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read(file):\n",
    "    return pd.read_csv(file)\n",
    "\n",
    "#features.set_index(['Index'], inplace = True)\n",
    "#features.drop(columns = ['Index'], inplace = True)\n",
    "\n",
    "features = read('Pmax_forward_Final.csv')\n",
    "features.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['α [°]', 'H [mm]', 'b [mm]', 'Ls [mm]', 'γ [N/mm3]', 'Pmax [N]',\n",
       "       'Vroot [mm3]', 'φ [°]'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#summary statistics\n",
    "features.describe()\n",
    "features.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.options.display.max_rows = 181\n",
    "pd.options.display.max_columns = 30\n",
    "#features.sort_values(by = \"L [mm]\", ascending = True, inplace = True)\n",
    "#display(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding\n",
    "pd.options.display.max_columns = 181\n",
    "pd.options.display.max_rows = 181\n",
    "\n",
    "if 'n [count]' in features.columns and 'Material' in features.columns:\n",
    "    features = pd.get_dummies(features, columns = ['n [count]', 'Material'])\n",
    "elif 'n [count]' in features.columns:\n",
    "    features = pd.get_dummies(features, columns = ['n [count]'])\n",
    "elif 'Material' in features.columns:\n",
    "    features = pd.get_dummies(features, columns = ['Material'])\n",
    "#features.head(5)\n",
    "#display(features)\n",
    "#print_shape(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target pmax/f\n",
    "pmax = np.array(features['Pmax [N]']).reshape(1, -1)\n",
    "\n",
    "#Remove labels from the features\n",
    "features = features.drop('Pmax [N]', axis = 1)\n",
    "feature_list = list(features.columns)\n",
    "features = StandardScaler().fit_transform(features)\n",
    "pmax = Normalizer().fit_transform(pmax).reshape(-1, 1)\n",
    "#pca = PCA(n_components = 11)\n",
    "#principalComponents = pca.fit_transform(features)\n",
    "#features = pd.DataFrame(data = principalComponents, columns = ['pc1', 'pc2','pc3','pc4','pc5','pc6','pc7','pc8','pc9','pc10','pc11'])\n",
    "#display(features)\n",
    "#print(pca.explained_variance_ratio_.cumsum())\n",
    "\n",
    "#Covert to numpy arrays\n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into training set and testing set \n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, pmax, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (132, 7)\n",
      "Training Labels Shape: (132, 1)\n",
      "Testing Features Shape: (45, 7)\n",
      "Testing Labels Shape: (45, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1100, num = 11)]\n",
    "max_depth = [int(x) for x in np.linspace(1, 10, num = 10)]\n",
    "max_features = [\"auto\", \"sqrt\", 2, 3, 4]\n",
    "min_samples_leaf = [int(x) for x in np.linspace(start = 1, stop = 5, num = 5)]\n",
    "min_samples_split = [int(x) for x in np.linspace(start = 1, stop = 5, num = 5)]\n",
    "print(min_samples_leaf)\n",
    "print(max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'max_depth': max_depth,\n",
    "    'max_features': max_features,\n",
    "    'min_samples_leaf': min_samples_leaf,\n",
    "    'min_samples_split': min_samples_split,\n",
    "    'n_estimators': n_estimators,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator = gb, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 13750 candidates, totalling 41250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 304 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1034 tasks      | elapsed:   24.3s\n",
      "[Parallel(n_jobs=-1)]: Done 2166 tasks      | elapsed:   49.3s\n",
      "[Parallel(n_jobs=-1)]: Done 3554 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 5365 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 6911 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 8404 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 10441 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 13162 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done 15871 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=-1)]: Done 18753 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=-1)]: Done 20928 tasks      | elapsed: 10.8min\n",
      "[Parallel(n_jobs=-1)]: Done 25174 tasks      | elapsed: 13.3min\n",
      "//anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done 29283 tasks      | elapsed: 15.6min\n",
      "[Parallel(n_jobs=-1)]: Done 32364 tasks      | elapsed: 17.4min\n",
      "[Parallel(n_jobs=-1)]: Done 36012 tasks      | elapsed: 19.7min\n",
      "[Parallel(n_jobs=-1)]: Done 41250 out of 41250 | elapsed: 22.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=GradientBoostingRegressor(), n_jobs=-1,\n",
       "             param_grid={'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
       "                         'max_features': ['auto', 'sqrt', 2, 3, 4],\n",
       "                         'min_samples_leaf': [1, 2, 3, 4, 5],\n",
       "                         'min_samples_split': [1, 2, 3, 4, 5],\n",
       "                         'n_estimators': [100, 200, 300, 400, 500, 600, 700,\n",
       "                                          800, 900, 1000, 1100]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(train_features, train_labels.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor(max_features='sqrt', min_samples_leaf=3,\n",
      "                          min_samples_split=5, n_estimators=800)\n"
     ]
    }
   ],
   "source": [
    "best_grid = grid_search.best_estimator_\n",
    "print(best_grid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
